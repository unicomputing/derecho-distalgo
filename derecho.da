# This is a DistAlgo implementation of Derecho, as described in
# Derecho: Fast State Machine Replication for Cloud Services
# SAGAR JHA, Cornell University, USA
# JONATHAN BEHRENS, Cornell University, USA and MIT, USA
# THEO GKOUNTOUVAS, MATTHEW MILANO, WEIJIA SONG, EDWARD TREMEL,
# ROBBERT VAN RENESSE, SYDNEY ZINK, and KENNETH P. BIRMAN,
# Cornell University, USA
# ACM Transactions on Computer Systems, Vol. 36, No. 2. Article 4. Publication date: March 2019.
# http://www.cs.cornell.edu/ken/derecho.pdf
# Implementation of the View Change Protocol as listed under section A.1 to A.4
# Pages 32 to 37

import sys
import random

class Slot:
  """A.2.1. SST Structure. SMC uses two fields, slots and received_num. 
  slots is a vector of window_size slots, 
  each of which can store a message of up to max_message_size characters. 
  The index associated with a slot is used to signal that a new message is present in that slot: 
  For example, if a slot’s index had value k and transitions to k + 1, 
  then a new message is available to be received.
  The vector received_num holds counters of the number of messages received from each node.
  """
  def __init__(self):
    self.index = -1  #- index position of this slot in vector of slots
    self.buf = None  #- message in this slot, of up to max_message_size characters
    self.size = 0    #- size of message in this slot, up to max_message_size


class SSTRow:                                                             # IMPROV --- The variables and their initial values are not explicitly mentioned in the Paper
  '''source?
  Derecho uses protocols that run on a novel replicated data structure called the shared state table, or SST. 
  The SST offers a tabular distributed shared memory abstraction. Every member of the top-level group holds its own replica of the entire table, in local memory.
  Within this table, there is one identically formatted row per member. 
  A member has full read/write access to its own row but is limited to read-only copies of the rows associated with other members
  A list of SSTRows form a Shared State Table (SST)
  A copy of the SST is stored by each Node
  SST as per A.1.1 SST
  '''
                                      # column_name->string|string[int] // e.g. wedged or latest_received_index[3]
                                      # sst_row->sst[row_rank]
                                      # row_rank->int
                                      # sst_column->sst[*].column_name
                                      # sst_entry->sst_row.column_name // e.g. sst[0].stable_msg_index[0]
  def __init__(self, nprocess, window_size):
    #- each field is a column name (?)
    # suspected: Stores true if the Node suspects a failure of any other Node against its index
    self.suspected = [False] * nprocess  # (but this is a list)
    self.num_committed = 0  #- number of changes committed by the Node (what Node?), as suggested by the Leader
    self.num_acked = 0      #- number of changes acknowleged by the Node (what Node?), as suggested by the Leader
    self.received_num = [0] * nprocess  #- list, of number of messages received from each node (by lengh 1?)
    self.wedged = False     #- whether the Node has wedged its SST
    self.changes = []       #- list of node ids of crashed/new nodes
    self.num_changes = 0    #- number? of changes (crashes/additions) of Nodes  (what Nodes?)
    # num_installed: number of 'changes' applied or installed to the current Node
    self.num_installed = 0
    # min_latest_received: The min index of message received by all processes
    self.min_latest_received = [-1] * nprocess
    # latest_received_index: the list of indices of the last message received from each node
    self.latest_received_index = [-1]*nprocess
    # ragged_edge_computed: Stores True if ragged edge has been computed for a node
    self.ragged_edge_computed = True
    # latest_delivered_index: The index of the latest message successfully delivered by the Node
    self.latest_delivered_index = -1
    # global_index: The global message index counter, used for total ordering of messages in the system
    self.global_index = -1
    # slots: stores the messages received
    self.slots = [Slot()]*window_size
    # node: Reference to the Node indicated by the row in the SST
    self.node = None



class View():                               # IMPROV This Data structure is not mentioned in the psuecode, but used
  '''
  A view holds the metadata of an epoch
  '''
  def __init__(self, nprocess, leader_rank=0):
    # max_rank: stores the max rank in the SST table in the current view
    self.max_rank = nprocess
    # leader_rank: stores the index of the leader in the currrent view
    self.leader_rank = 0
    # failed: stores if a process is deemed 'failed' in the view
    self.failed = [False] * nprocess
    # wedged: boolean to note if the view is 'wedged' by the system
    self.wedged = False
    # members: Maintains a list of members in the view
    self.members = [None] * nprocess


class Node(process):

  def write_sst(row, attr, val, index=None):
    '''
    - Simulate RDMA based write to an SST
    - Every Node owns a row in the SST and is the only writer 
    - Every local update to a cell has to be multicasted to all other Nodes to update their copy of the row
    - Derecho uses RDMA to update across Nodes, we simulate this uing the below functions write_sst and write_view
    - Every update to a cell is written locally and then multicasted to all Nodes for them to update their local copies
    '''
    # update the local SST
    if index is not None:
      newval = getattr(sst[row], attr)
      newval[index] = val
      setattr(sst[row], attr, newval) 
    else:
      setattr(sst[row], attr, val) 
    message =  ('rdma_write_sst', row, attr, val, index)
    # output("sending message: " , message, " to ", (nodes-set([self])))
    # Cast the update message to all the Nodes
    send(message, to=(nodes-set([self])))

  def write_view(attr, val, index=None):
    '''
    - Similate RDMA based write to a View
    - Takes the attributes, value and index and update the view
    '''
    # update the local view
    if index is not None:
      newval = getattr(curr_view, attr)
      newval[index] = val
      setattr(curr_view, attr, newval) 
    else:
      setattr(curr_view, attr, val) 
    # Cast the update message to all the Nodes
    send(('rdma_write_view', attr, val, index), to=(nodes-set([self])))

  
  def min_not_failed(attr): (why not called column or col? paper called "attr"?)
    '''
    - Calculates the min value for a columnn for non-failed Nodes in an SST (non-failed? Nodes? an SST? can you write more precisely, check if mine below is right)
    - Takes the column name as a param
    '''
    '''- min value of column attr for non-suspected nodes in the sst of this node'''
    return min({getattr(sst[row], attr) for row in range(len(sst)) if not sst[my_rank].suspected[row]})

  def _min(attr, index=None):
    '''
    - Calculates the min value for a column for all Nodes in an SST
    - Takes the column name as a param, and index if the column holds a list
    '''
    if index is None:
      return min({getattr(sst[row], attr) for row in range(len(sst))})
    else:
      return min({getattr(sst[row], attr)[index] for row in range(len(sst))})

  def logical_and_not_failed(attr):
    '''
    - Calculates the the logical AND of all values in a columnn for non-failed Nodes in an SST
    - Takes the column name as a param
    '''
    return all(getattr(sst[row], attr) for row in range(len(sst)) if not sst[my_rank].suspected[row])

  def logical_or(attr):
    '''logical OR of all values in a columnn in an SSTColumn to be passed an a paramter''' (the code doesn't sound to do the comment)
    return some(v in sst, has=getattr(v,attr))

  def min_with_val(attr, val):
    '''
    - Calculates the min row with a given value for a column in the SST
    - Column and value to be checked against to be passed an a paramter
    '''
    return min({row for row in range(len(sst)) if getattr(sst[row], attr) == val})

  def Count(attr, val):
    '''
    - Calculates the count of rows with a given value for a column
    - Column name and the value to be passed an a paramter
    '''
    return len({row for row in range(len(sst)) if getattr(sst[row], attr) == val})

  def get_max_gi():
    '''- max of (sst[my_rank].min_latest_received[n] ∗ |G| + n) over n in 1..|G|'''
    if len(G) < 1:
      return 0
    return max(sst[my_rank].min_latest_received[n] * len(G) + n) for n in range(len(G)))

  def gi(i, k):
    '''global index of a message given ... i and ... k'''
    return i*len(G)+k                             # gi (M(i, k)) = i ∗ |G| + k

  
  # A.2.2 Initialization
  def setup(nodes, nprocess, my_rank, window_size):
                                          # for i in 1 to n {
    # the idea is replicated below                        #   for j in 1 to n {
                                          #    sst[i].received_num[j] = -1
                                          #  for k in 1 to window_size {
                                          #    sst[i].slots[k].buf = nullptr
                                          #    sst[i].slots[k].index = 0 }}
    self.sst = [SSTRow(nprocess, window_size)]*nprocess
    self.sent_num = -1                     # sent_num = -1
    self.curr_view = View(nprocess)
    self.G = nodes
    self.msgs = {}
    self.max_msg_size = 10
    write_view('members', self, my_rank)
    write_sst(my_rank, 'node', self)
    output("s:", sst[0].node, sst[1].node, sst[2].node)

  def run():
    output("my_rank: ", str(my_rank))
    while True:
      if await(sst[curr_view.leader_rank].num_changes > sst[my_rank].num_acked and curr_view.leader_rank != my_rank):  # A.4.2 when (sst[leader_rank].num_changes > sst[my_rank].num_acked); if(curr_view.leader_rank != my_rank)
        output("leader proposed a new change")                                 # |= leader proposed a new change
        leader_rank = curr_view.leader_rank  
        write_sst(my_rank, 'num_acked', sst[leader_rank].num_changes)         # IMPROV :  believe its missed as it is required to terminate
        write_sst(my_rank, 'num_changes', sst[leader_rank].num_changes)       # sst[my_rank].num_changes = sst[leader_rank].num_changes;
        # copy entire changes vector from the leader's row
        write_sst(my_rank, 'changes', sst[leader_rank].changes)               # sst[my_rank].changes = sst[leader_rank].changes;
        write_sst(my_rank, 'num_committed', sst[leader_rank].num_committed)   # sst[my_rank].num_committed = sst[leader_rank].num_committed;
        curr_view.wedged = True                                               # curr_view.wedge();
        write_sst(my_rank, 'wedged', True)                                     # sst[my_rank].wedged = true;
        # acknowledged leader's proposal and wedged the current view
      elif curr_view.leader_rank == my_rank and min_not_failed('num_acked') > sst[my_rank].num_committed:         # A.4.2 when (curr_view.leader_rank == my_rank and MinNotFailed(sst[∗].num_acked) > sst[my_rank].num_committed) 
        #acknowledge a new proposal                                       # |= K U\F ( acknowledged a new proposal )
        output("commit_proposal_leader")
        write_sst(my_rank, 'num_committed', min_not_failed('num_acked'))   # sst[my_rank].num_committed = MinNotFailed(sst[∗].num_acked);
        #commited acknowledged proposals
      elif sst[curr_view.leader_rank].num_committed > sst[my_rank].num_installed:                                     # A.4.2 when (sst[my_rank].num_committed[leader_rank] > sst[my_rank].num_installed[my_rank]) 
        # leader committed a new membership  # 22 |= leader committed a new membership change
        curr_view.wedged = True                   # curr_view.wedge();
        write_sst(my_rank, 'wedged', True)         # sst[my_rank].wedged = true;
        await(logical_and_not_failed('wedged'))    # when (LogicalAndNotFailed(sst[∗].wedged) == true) {
        output("terminate epoch")                 # / |= K U\F ( current view is wedged)
        terminate_epoch()                         # terminate_epoch
      elif timeout(4):                                                                                                       # IMPROV
        receive_msg() # always - but  called only once to help terminate
        stability_delivery() # always - but  called only once to help terminate
        send('done', to=parent())
        break
    #output("SST: ", sst)
    output("Final agreed new view: ", curr_view.members)
    output('terminating NODES')


  # A.2.3 Sending. First the sending node reserved one of the slots:
  # method for resolving the available slot before sending the message
  def get_buffer(msg_size):                       # char* get_buffer(msg_size) {
    output("get_buffer")
    if msg_size > max_msg_size: return None       #   assert(msg_size <= max_msg_size);
                                                  #   // A Slot can be reused if the previos message in that slot was received by everyone
                                                  #   // Combine it with the FIFO ordering of messages
    completed_num = _min("received_num", my_rank) #   completed_num = Min{sst[*].received_num[my_rank]};
    if sent_num - completed_num < window_size:    #   if (sent_num - completed_num < window_size) {
      return None                                 #     return nullptr;
                                                  #   }
    slot = (sent_num + 1) % window_size           #   slot = (sent_num + 1) % window_size;
    sst[my_rank].slots[slot].size = msg_size      #   sst[my_rank].slots[slot].size = msg_size;
    return sst[my_rank].slots[slot].buf           #   return sst[my_rank].slots[slot].buf;
                                                  # }
  
  # method to increment the slot and send the message
  def send_msg():                                 # void send() {
    output("send_msg")
    slot = (sent_num + 1) % window_size           #   slot = (sent_num + 1) % window_size;
    sst[my_rank].slots[slot].index += 1           #   sst[my_rank].slots[slot].index++;
    write_sst(my_rank, "slots", sst[my_rank].slots[slot], slot)      
    sent_num += 1                                 #   sent_num++;
                                                  # }
  
  
  # A.2.4 Receiving
 
  # always
  # Process to receives a message, increments the current slot based on thewindow size and receives the message
  def receive_msg():
    output("receive_msg")
    for i in range(nprocess):                                                         # for i in 1 to n {
      slot = (sst[my_rank].received_num[i]+1)%window_size                             #  slot = (sst[my_rank].received_num[i]+1)%window_size
    if sst[i].slots[slot].index == (sst[my_rank].received_num[i]+1)/(window_size+1):  #  if(sst[si].slots[slot].index == (sst[my_rank].received_num[i]+1)/(window_size+1)){
      write_sst(my_rank, "received_num", sst[my_rank].received_num[i]+1, i)           #    ++sst[my_rank].received_num[i];
      recv((i, sst[my_rank].received_num[i]))                                         #    recv(M(i, sst[my_rank].received_num[i])); }}

  # Method to calculate the minimun index received by the node and the lagging node
  def get_min_idx_rec():                               # (min,argmin) i sst[my_rank].latest_received_index[i];
    min_ind = sst[my_rank].latest_received_index[0]
    lagging_node = 0
    for i in range(1, nprocess):
      if sst[my_rank].latest_received_index[i] < min_ind:
        min_ind = sst[my_rank].latest_received_index[i]
        lagging_node = i
    return min_ind,lagging_node


  # A.3 Atomic Multicast Delivery in the Steady Stat
  # A.3.1 Receive
  # Receives a message and adds it to the global message queue
  def recv(M):                                         # on recv(M(i,k)) {
    output("recv")                                     #   // |= K_me(Received M(i,k))
    (i, k) = M
                                                       #   // store the message to deliver later
    msgs[gi(i, k)] = (i, k)                            #   msgs[hi(M(i,k))] = M(i,k);
    write_sst(my_rank, "latest_received_index", k, i)  #   sst[my_rank].latest_received_index[i ] = k;    
                                                       #   // calculate global index of the message in the global round−robin ordering
    min_index_received, lagging_node_rank = get_min_idx_rec()
                                                       # (min_index_received, lagging_node_rank) = (min,argmin) i sst[my_rank].latest_received_index[i];  
    write_sst(my_rank, "global_index", (min_index_received + 1)*len(G)+lagging_node_rank-1)
                                                       # sst[my_rank].global_index = (min_index_received + 1) ∗ |G| + lagging_node_rank − 1;
                                                       #   // |= K_me (Received all messages M(i,k) s.t. дi(M(i,k)) ≤ sst[my_rank].global_index)

  def deliver_upcall(message):
    output(" deliver_upcall ", message)                # IMPROV: No implementation provided in the pseudocode

  # A.3.2 Stability and Delivery
  # Calculates the next global index for message delivery                               # always
  def stability_delivery():
    stable_msg_index = _min("global_index")   #   stable_msg_index = Min{sst[∗].global_index}
                                              #   // |= K_me (∀p ∈ G : K p (Received all messages M(i,k) s.t. дi(M(i,k)) ≤ sst[my_rank].global_index))
    for msg in msgs:                          #   for (msg : msgs) {
      if msg <= stable_msg_index:             #     if (msg.global_index <= min_stable_msg_index) {
        deliver_upcall(msgs[msg])             #       deliver_upcall(msg);
        del msgs[msg]                         #       msgs.remove(msg.global_index);
                                              #     }
                                              #   }
    write_sst(my_rank, "latest_delivered_index", stable_msg_index)
                                              #   sst[my_rank].latest_delivered_index = stable_msg_index
                                              # }
                                              # // |= K_me (Delivered all messages ≤ sst[my_rank].latest_delivered_index)

  
  # A.4 View Change Protocol
  # A.4.1 Failure Handling and Leader Proposing Changes for Next View

 
  #  Receives a failure trigger
  #  This is to simulate: polling on the SST table for not receving a message for a time-period 
  #  from one of the servers
  def receive(msg=('failure', r)):              # every 1 millisecond {
                                                #   post RDMA write with completion time to every SST Row that is not frozen
    if r != my_rank: # ?                        #   if (no completion polled from row r) {
      output("freeze") # no impl mentioned      #     sst.freeze(r);
      output("Received failure of ", r)              
      report_failure(r)                         #     report_failure(r);
                                                #   }
                                                # }

  # method to update the suspected field upon noticing a node failure
  def report_failure(r):                                # report_failure(r) {
    output("in report failure")
                                                        #   // local node suspects node that owns the row report              
    write_sst(my_rank, 'suspected', True, r)            #   sst[my_rank].suspected[r] = true;
    total_failed = Count('suspected', True)             #   total_failed = Count(sst[∗].suspected, true);
    if total_failed >= (nprocess + 1)/2:                #   if (total_failed >= (num_members + 1)/2) {
      output("throw derecho_partitioning_exception")    #     throw derecho_partitioning_exception;
      return                                            #   }
    suspect()                                           # IMPROV

  #  returns the node that r believes to be the leader, on the basis of the current sst
  #  Notice that becasue of asynchrony in the sst update propagations, callers other than r itself might be using
  #  old version's of r's suspicion set, in which cse the caller could obtain an old leader belif of r's.
  #  This is safe because leader beliefs are monitonic (they are ascending, in rank order)
  def find_new_leader(my_rank):                # find_new__leader(r) {
    for i in range(len(sst)): #sst?            #   for (int i = 0; i < curr_view.max_rank; ++i) {
      if sst[my_rank].suspected[i]: continue   #     if(sst[r].suspected[i]) continue;
      else: return i                           #     else return i
                                               #   }
                                               # }

  # wait until all non-suspected nodes comsider me to be the leader.
  # implies that the new leader takes action only after every healthy node has
  # pushed final nReceived data to it
  # updates the view at the end of the current leader                                    #always
  def leader_selection():
    output("leader_selection")
    new_leader = find_new_leader(my_rank)                                                # new_leader = find_new_leader(my_rank)
    if new_leader != curr_view.leader_rank and new_leader == my_rank:                    # if(new_leader != curr_view.leader_rank && new_leader == my_rank)
      all_others_agree = True                                                           # bool all_others_agree = true
      #so as long as I continue to believe I will be leader
      while find_new_leader(my_rank) == my_rank:                                        # while(find_new_leader(my_rank) == my_rank)
        for r in range(len(sst)):                                                        # for(r: SST.rows){
          if not sst[my_rank].suspected[r]:                                              #   if(sst[my_row].suspected[r] == false)
            all_others_agree = all_others_agree and (find_new_leader(r) == my_rank)      #     all_others_agree &&= (find_new_leader(r) == my_rank)
        
        if all_others_agree:                                                             # if(all_others_agree)
          #Scan sst to learn prior proposals
          write_view('leader_rank', my_rank)                                            # curr_view.leader_rank = my_rank
          break                                                                          #   break

  # method to poll the suspected filed in the SST and propagate the status across the systems               # always
  def suspect():
    output("suspect")
    for r in range(len(sst)):                                     # for(every row r and s)
      for s in range(len(sst)):
        if sst[r].suspected[s]:                                   #  if(sst[r].suspected[s] == true)
          # failure propagation, local node also suspects s
          # and updates it SST row
          write_sst(my_rank, 'suspected', True, s)                #    sst[my_rank].suspected[s] = true

    for s in range(len(sst)):                                     # for(s=0; s < num_members; ++s)
      # if s is newly suspected
      if sst[my_rank].suspected[s] and (not curr_view.failed[s]): # sst[my_rank].suspected[s] == true and curr_view.failed[s] == false
                                                                  # freeze(s)
        # report_failure(s)                                          # report_failure(s)
        # mark s as failed in the current view
        curr_view.failed[s] = True                                 # curr_view.failed[s] = true
        curr_view.wedged = True                                   # curr_view.wedge()
        write_sst(my_rank, 'wedged', True)                         # sst[my_rank].wedged = true

        leader_selection()                                         # IMPROV

        if curr_view.leader_rank == my_rank and s not in sst[my_rank].changes:           # if(curr_view.leader_rank == my_rank and sst[my_rank].changes.contains(s) == false)
          next_change_index = sst[my_rank].num_changes - sst[my_rank].num_installed         # next_change_index = sst[my_rank].num_changes − sst[my_rank].num_installed;
          #not required in python for position
          changes = sst[my_rank].changes                               
          changes.append(s) 
          write_sst(my_rank, 'changes', changes)                       # sst[my_rank].changes[next_change_index] = s #id of node owning S
          num_changes = sst[my_rank].num_changes + 1                   
          write_sst(my_rank, 'num_changes', num_changes)              # sst[my_rank].num_changes++;
          #proposed a new membership change and wedged the current view


  # calculate next view membership
  def terminate_epoch():
    leader_rank = curr_view.leader_rank
    committed_count = sst[leader_rank].num_committed - (sst[leader_rank].num_installed)          # committed_count = sst[leader_rank].num_committed − sst[leader_rank].num_installed;
    sst[my_rank].num_installed = sst[leader_rank].num_committed                      # IMPROV
    next_view = View(nprocess - len(sst[my_rank].changes))
    next_view.leader_rank = curr_view.leader_rank
    next_view.members = curr_view.members
    for change_index in range(len(sst[my_rank].changes)):              # for (change_index = 0; change_index < committed_count; change_index++) {
      node_id = next_view.members[sst[my_rank].changes[change_index]] # node_id = sst[my_rank].changes[change_index]; 
      output("delete node: ", node_id, sst[my_rank].changes[change_index])

    # if node already a member, the change is to remove the node;
      if node_id in next_view.members:                         # if (curr_view.contains(node_id) == true) {
        next_view.members.remove(node_id)                     # next_view.members = curr_view.members; # new_view.members.remove(node_id);
        output("after remove",  next_view.members)
      else:                                                    # else 
        next_view.members.append(node_id)                     # next_view.members.append(node_id);  

    if leader_rank == my_rank:                                 # if (leader_rank == my_rank) {
      leader_ragged_edge_cleanup()                             # leader_ragged_edge_cleanup();
    elif await(sst[leader_rank].ragged_edge_computed):         # else when (sst[leader_rank].ragged_edge_computed == true) 
      non_leader_ragged_edge_cleanup()                         # { non_leader_ragged_edge_cleanup(); }
    curr_view = next_view                                     # curr_view = next_view;
    #new view installed
  
  # Cleans up and corrects the ragged edge due to failure, for the leader node
  def leader_ragged_edge_cleanup():                           # leader_ragged_edge_cleanup() {
    output("leader_ragged_edge_cleanup ", self)
    if logical_or("ragged_edge_computed"):                     # if (LogicalOr(sst[∗].ragged_edge_computed) == true) {
      rank = min_with_val("ragged_edge_computed", True)        # Let rank be s.t. sst[rank].ragged_edge_computed is true
      # copy min_latest_received from the node that computed the ragged edge
      for n in range(len(G)):                                 # for (n = 0; n < |G|; ++n) {
        write_sst(my_rank, "min_latest_received", sst[rank].min_latest_received[n], n)       # sst[my_rank].min_latest_received[n] = sst[rank].min_latest_received[n];
      write_sst(my_rank, "ragged_edge_computed", True)        # sst[my_rank].ragged_edge_computed = true;
    else:                                                     # else {
      for n in range(len(G)):                                 # for (n = 0; n < |G|; ++n) {
        write_sst(my_rank, "min_latest_received", _min("latest_received_index", n), n)      # sst[my_rank].min_latest_received[n] = Min(sst[∗].latest_received_index[n]);
        # // |= K me ( sst[my_rank].min_latest_received[n] number of messages from n are safe for delivery)
      write_sst(my_rank, "ragged_edge_computed", True)        # sst[my_rank].ragged_edge_computed = true;
    deliver_in_order()                                         # deliver_in_order();

  # Cleans up and corrects the ragged edge due to failure, for non-leader nodes
  def non_leader_ragged_edge_cleanup():                       # non_leader_ragged_edge_cleanup() {
    output("non_leader_ragged_edge_cleanup ", self)
    leader_rank = curr_view.leader_rank
    # copy from the leader
    for n in range(len(G)):                                   # for (n = 0; n < |G|; ++n) {
      write_sst(my_rank, "min_latest_received", sst[leader_rank].min_latest_received[n], n)   # sst[my_rank].min_latest_received[n] = sst[leader_rank].min_latest_received[n]; }
    write_sst(my_rank, "ragged_edge_computed", True)          # sst[my_rank].ragged_edge_computed = true;
    deliver_in_order()                                         # deliver_in_order();

  # Once the ragged edge has been cleaned up, the pedning messages are delivered
  def deliver_in_order():                                         # deliver_in_order() {
    output("deliver_in_order")
    curr_global_index = sst[my_rank].latest_delivered_index       # curr_global_index = sst[my_rank].latest_delivered_index;
    max_global_index = get_max_gi()                               # max_global_index = max over n of (sst[my_rank].min_latest_received[n] ∗ |G| + n);
    for global_index in range(curr_global_index + 1,  max_global_index + 1):       # for (global_index = curr_global_index + 1; global_index <= max_global_index; ++global_index) {
      sender_index = global_index/len(G)                           # sender_index = global_index / |G|;
      sender_rank = global_index%len(G)                           # sender_rank = global_index % |G|;
      if (sender_index <= sst[my_rank].min_latest_received[sender_rank]):                # if (sender_index <= sst[my_rank].min_latest_received[sender_rank]) {
        deliver_upcall(msgs[global_index])                         # deliver_upcall(msgs[global_index]);

  # Recieves message for an RDMA write, update the local SST
  def receive(msg = ('rdma_write_sst', row, attr, val, index)):
    #update the local SST
    output("Received message:" , ('rdma_write_sst', row, attr, val, index))
    if index is not None:
      newval = getattr(sst[row], attr)
      newval[index] = val
      setattr(sst[row], attr, newval) 
    else:
      setattr(sst[row], attr, val) 

  # Recieves message for an RDMA write, update the local View
  def receive(msg = ('rdma_write_view', attr, val, index)):
    #update the local view
    output("Received message:", ('rdma_write_view', attr, val, index))
    if index is not None:
      newval = getattr(curr_view, attr)
      newval[index] = val
      setattr(curr_view, attr, newval) 
    else:
      setattr(curr_view, attr, val) 


# This process is to simulate a failure scenario
class Sim(process):
  def setup(nodes): pass
  
  def run():
    output(nodes)
    #failing last node
    send(('failure', len(nodes)-1), to= nodes)
    output("Sent failure message to nodes")


def main():
  '''
  accepts the number of nodes as input paramters during runtime 
  '''
  num_nodes = int(sys.argv[1]) if len(sys.argv) > 1 else 1
  window_size = 5
  nodes = new(Node, num= num_nodes)
  for (rank, node) in enumerate(nodes):
    setup(node, (nodes, num_nodes, rank, window_size))
  start(nodes)
  sim = new(Sim, (nodes,), num=1)
  start(sim)
  await(len(setof(a, received('done', from_ =a))) == len(nodes) - 1)
  #end(sim|nodes)
